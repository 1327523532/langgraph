{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396e20d9-8684-40ea-a46a-e3dfa36ed5a6",
   "metadata": {},
   "source": [
    "## Existing Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d642e6af-217a-4414-a78c-509b44155eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonchase/workplace/langchain/libs/core/langchain_core/_api/beta_decorator.py:160: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n",
      "/Users/harrisonchase/workplace/langchain/libs/core/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from permchain.langgraph import Graph, END\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "from langchain_core.agents import AgentFinish\n",
    "# Define decision-making logic\n",
    "def should_continue(data):\n",
    "    # Logic to decide whether to continue in the loop or exit\n",
    "    if isinstance(data['agent_outcome'], AgentFinish):\n",
    "        return \"exit\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    \n",
    "def execute_tools(data):\n",
    "    agent_action = data.pop('agent_outcome')\n",
    "    observation = {t.name: t for t in tools}[agent_action.tool].invoke(agent_action.tool_input)\n",
    "    data['intermediate_steps'].append((agent_action, observation))\n",
    "    return data\n",
    "    \n",
    "    \n",
    "\n",
    "# Define agents\n",
    "agent = RunnablePassthrough.assign(\n",
    "    agent_outcome = agent_runnable\n",
    ")\n",
    "\n",
    "\n",
    "# Define a new graph\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", execute_tools)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"exit\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge('tools', 'agent')\n",
    "\n",
    "chain = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46bd262-9605-4449-9391-f6b6e0fe440e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in sf',\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\":\"weather in San Francisco\"}'}})]),\n",
       "   [{'url': 'https://www.oddsshopper.com/articles/nfl/los-angeles-rams-san-francisco-49ers-weather-report-01-07-2024',\n",
       "     'content': \"find a current San Francisco-Los Angeles weather report.  Weather Forecasted for the Rams-49ers Football Game  November 9, 2023 7:58 am 7:58 am  Rams-49ers Weather ReportJanuary 07, 2024 | 2:03 AM by OddsShopper Staff. This Week 18 NFL game is to be played in Santa Clara, CA at Levi's Stadium. Below you can find a current San Francisco-Los Angeles weather report. üèà Game time: 4:25PM EST: üìÖ Game date: Sunday, January 7th, 2024: ... 01 Bears vs Packers 22:41 Chiefs vs Chargers 25:08 Broncos vs Raiders\"}]),\n",
       "  (AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'current weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'current weather in San Francisco'}`\\nresponded: It seems that the search results did not provide the current weather in San Francisco. Let me try another source to get the accurate weather information for San Francisco.\\n\\n\", message_log=[AIMessage(content='It seems that the search results did not provide the current weather in San Francisco. Let me try another source to get the accurate weather information for San Francisco.', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\":\"current weather in San Francisco\"}'}})]),\n",
       "   [{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/',\n",
       "     'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 07-01-2023 54¬∞F to 56¬∞F. 08-01-2023 52¬∞F to 58¬∞F. 09-01-2023 54¬∞F to ...'}]),\n",
       "  (AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'current weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'current weather in San Francisco'}`\\nresponded: I found the current weather information for San Francisco. However, it seems to be showing historical weather data rather than the current weather. Let me try another search to get the most accurate and up-to-date weather information for San Francisco.\\n\\n\", message_log=[AIMessage(content='I found the current weather information for San Francisco. However, it seems to be showing historical weather data rather than the current weather. Let me try another search to get the most accurate and up-to-date weather information for San Francisco.', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\":\"current weather in San Francisco\"}'}})]),\n",
       "   [{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/',\n",
       "     'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 07-01-2023 54¬∞F to 56¬∞F. 08-01-2023 52¬∞F to 58¬∞F. 09-01-2023 54¬∞F to ...'}])],\n",
       " 'agent_outcome': AgentFinish(return_values={'output': 'It seems that the search results are still not providing the current weather in San Francisco. I apologize for the inconvenience. I recommend using a trusted weather website or app to get the most accurate and up-to-date weather information for San Francisco.'}, log='It seems that the search results are still not providing the current weather in San Francisco. I apologize for the inconvenience. I recommend using a trusted weather website or app to get the most accurate and up-to-date weather information for San Francisco.')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e5e80f-747a-41ee-a559-e43f63415857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tools': {'input': 'what is the weather in sf', 'intermediate_steps': [], 'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\":\"weather in San Francisco\"}'}})])}}\n",
      "{'agent': {'input': 'what is the weather in sf', 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\":\"weather in San Francisco\"}'}})]), [{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/', 'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 07-01-2023 54¬∞F to 56¬∞F. 08-01-2023 52¬∞F to 58¬∞F. 09-01-2023 54¬∞F to ...'}])]}}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"input\": \"what is the weather in sf\", \"intermediate_steps\": []}, output=[\"agent\", \"tools\"]):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996363b-de06-40dd-a2cf-17837233894b",
   "metadata": {},
   "source": [
    "### Make it always call a specific tool first\n",
    "\n",
    "Let's imagine that we ALWAYS want to call a specific tool to start. We can do that easily by modifying the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "147f39b2-acf0-4408-922f-218f480f1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentActionMessageLog\n",
    "\n",
    "def first_agent(inputs):\n",
    "    inputs[\"agent_outcome\"] = AgentActionMessageLog(tool=\"tavily_search_results_json\", tool_input=inputs[\"input\"], log=\"\", message_log=[])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229c2944-4baf-4f54-96c6-bb600c1c6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"first_agent\", first_agent)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", execute_tools)\n",
    "\n",
    "workflow.set_entry_point(\"first_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"exit\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge('first_agent', 'tools')\n",
    "workflow.add_edge('tools', 'agent')\n",
    "\n",
    "chain = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bd7e0bf-88e1-48e8-a1e8-9983975bb03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tools': {'input': 'what is the weather in sf', 'intermediate_steps': [], 'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input='what is the weather in sf', log='', message_log=[])}}\n",
      "{'agent': {'input': 'what is the weather in sf', 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input='what is the weather in sf', log='', message_log=[]), [{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/', 'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  Seasonal average climate and temperature of San Francisco in january  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 07-01-2023 54¬∞F to 56¬∞F. 08-01-2023 52¬∞F to 58¬∞F. 09-01-2023 54¬∞F to ...'}])]}}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"input\": \"what is the weather in sf\", \"intermediate_steps\": []}, output=[\"agent\", \"tools\", \"first_agent\"]):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c3886-71d1-4539-80dd-111e55cc3a85",
   "metadata": {},
   "source": [
    "## Reflexion Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f96e81-4a20-4599-a625-8d18df6fa76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonchase/workplace/langchain/libs/core/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, BaseMultiActionAgent, Tool\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    max_tokens=2000,\n",
    "    max_retries=100,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)\n",
    "\n",
    "NEXT_STEP_TEMPLATE = \"\"\"You are expert researcher trying answer a question ~250 words. You are asked to answer the following question: {question}\n",
    "\n",
    "The way you are going to answer the question is as follows:\n",
    "\n",
    "1. Revise your previous answer using the new information.\n",
    "    - You should use the previous critique to add important information to your answer.\n",
    "        _ You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
    "2. Reflect and critique your answer. Specifically, you should:\n",
    "    - Think about what is missing from your answer.\n",
    "    - Think about what is superfluous in your answer.\n",
    "    - Think about what search query you should use next to improve your answer.\n",
    "  Give your answer in exactly 2 parts. The first should address what is missing from your answer. The second should address what could be removed from your answer. Your should be VERY harsh as we really want to improve the answer.\n",
    "3. Give the search query you came up with to improve your answer.\n",
    "\n",
    "Previous steps: \n",
    "\n",
    "{previous_steps}\n",
    "\n",
    "===\n",
    "\n",
    "Format your answer as follows:\n",
    "\n",
    "Revised answer: [give your revised answer based on the previous critique and new information from the search engine then the \"References\" section]\n",
    "Critique: [give your harsh critique of your revised answer in 2 parts: what is missing and what is superfluous]\n",
    "Search query: [give the new search query you came up with to enter into the search engine to improve your answer. If you have more than one, make sure they are comma separated and in quotes]\n",
    "\n",
    "SAY NOTHING else please.\"\"\"\n",
    "\n",
    "INITIAL_ANSWER_TEMPLATE = \"\"\"You are expert researcher trying answer a question ~250 words. You are asked to answer the following question: {question}\n",
    "\n",
    "The way you are going to answer the question is as follows:\n",
    "\n",
    "1. Give a detailed in ~250 words.\n",
    "2. Reflect and critique your answer. Specifically, you should:\n",
    "    - Think about what is missing from your answer.\n",
    "    - Think about what is superfluous in your answer.\n",
    "    - Think about what search query you should use next to improve your answer.\n",
    "  Give your answer in exactly 2 parts. The first should address what is missing from your answer. The second should address what could be removed from your answer. Your should be VERY harsh as we really want to improve the answer.\n",
    "3. Give the search query you came up with to improve your answer.\n",
    "\n",
    "===\n",
    "\n",
    "Format your answer as follows:\n",
    "\n",
    "Answer: [give your initial answer]\n",
    "Critique: [give your harsh critique of your answer in 2 parts: what is missing and what is superfluous]\n",
    "Search query: [give the search query you came up with to improve your answer. If you have more than one, make sure they are comma separated and in quotes]\n",
    "\n",
    "SAY NOTHING else please.\"\"\"\n",
    "\n",
    "\n",
    "class ReflexionStep(BaseModel):\n",
    "    \"\"\"A single step in the reflexion process.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    critique: str\n",
    "    search_query: str\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Answer: {self.answer}\\nCritique: {self.critique}\\nSearch query: {self.search_query}\"\n",
    "\n",
    "def _parse_reflexion_step(output: str) -> tuple[str, str, str]:\n",
    "    # find answer using .split()\n",
    "    if (\"Answer:\" not in output and \"Revised answer:\" not in output) or not \"Critique:\" in output or not \"Search query:\" in output:\n",
    "        raise ValueError(f\"The output is not formatted correctly. Output: {output}\")\n",
    "    if \"Answer:\" in output:\n",
    "        answer = output.split(\"Answer:\")[1].split(\"Critique:\")[0].strip()\n",
    "    else:\n",
    "        answer = output.split(\"Revised answer:\")[1].split(\"Critique:\")[0].strip()\n",
    "    critique = output.split(\"Critique:\")[1].split(\"Search query:\")[0].strip()\n",
    "    search_query = output.split(\"Search query:\")[1].strip()\n",
    "    return answer, critique, search_query\n",
    "\n",
    "class ReflexionStepParser(BaseOutputParser[ReflexionStep]):\n",
    "    \"\"\"Parser for the reflexion step.\"\"\"\n",
    "\n",
    "    def parse(self, output: str) -> ReflexionStep:\n",
    "        \"\"\"Parse the output.\"\"\"\n",
    "        # try to find answer or initial answer\n",
    "        answer, critique, search_query = _parse_reflexion_step(output)\n",
    "        return ReflexionStep(\n",
    "            answer=answer, critique=critique, search_query=search_query\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7708fa95-547b-4bea-b126-3656de7d5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_chain = RunnablePassthrough.assign(\n",
    "    agent_outcome = ChatPromptTemplate.from_template(INITIAL_ANSWER_TEMPLATE) | llm | ReflexionStepParser() | (lambda x: AgentAction(\n",
    "                    tool=\"tavily_search_results_json\",\n",
    "                    tool_input=x.search_query,\n",
    "                    log=str(x),\n",
    "                ))\n",
    ")\n",
    "\n",
    "def prep_next(inputs):\n",
    "    intermediate_steps = inputs[\"intermediate_steps\"]\n",
    "    previous_steps = list[str]()\n",
    "\n",
    "    for i, (action, observation) in enumerate(intermediate_steps, start=1):\n",
    "        last_step_str = f\"\"\"Step {i}:\n",
    "\n",
    "{action.log}\n",
    "\n",
    "Search output for \"{action.tool_input}\":\n",
    "\n",
    "{observation}\"\"\"\n",
    "        previous_steps.append(last_step_str)\n",
    "\n",
    "    previous_steps_str = \"\\n\\n\".join(previous_steps)\n",
    "    inputs[\"previous_steps\"] = previous_steps_str\n",
    "    return inputs\n",
    "    \n",
    "next_chain = RunnablePassthrough.assign(\n",
    "    agent_outcome = prep_next | ChatPromptTemplate.from_template(NEXT_STEP_TEMPLATE) | llm | ReflexionStepParser() | (lambda x: AgentAction(\n",
    "                tool=\"tavily_search_results_json\",\n",
    "                tool_input=x.search_query,\n",
    "                log=str(x),\n",
    "            ))\n",
    ")\n",
    "\n",
    "def finish(inputs):\n",
    "    intermediate_steps = inputs[\"intermediate_steps\"]\n",
    "    last_action, _ = intermediate_steps[-1]\n",
    "    last_step_str = last_action.log\n",
    "    # extract answer\n",
    "    answer, _, _ = _parse_reflexion_step(last_step_str)\n",
    "\n",
    "    first_action, _ = intermediate_steps[0]\n",
    "    first_step_str = first_action.log\n",
    "    # extract answer\n",
    "    initial_answer, _, _ = _parse_reflexion_step(first_step_str)\n",
    "\n",
    "    return AgentFinish(\n",
    "        log=\"Reached max steps.\",\n",
    "        return_values={\"output\": answer, \"initial_answer\": initial_answer},\n",
    "    )\n",
    "\n",
    "\n",
    "def execute_tools(data):\n",
    "    agent_action = data.pop('agent_outcome')\n",
    "    observation = {t.name: t for t in tools}[agent_action.tool].invoke(agent_action.tool_input)\n",
    "    data['intermediate_steps'].append((agent_action, observation))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6cdd1cd-e480-4dd7-99b4-9018eb243b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': \"The current weather in San Francisco is experiencing colder than usual temperatures with a frost advisory and freeze warning in effect for the morning of January 7, 2024. The city's low is forecasted to remain around 41 degrees Fahrenheit [1]. This information is crucial for residents and visitors to take appropriate precautions against the cold. San Francisco's weather is generally mild with microclimates, but such advisories indicate that temperatures can drop significantly, especially in winter months. It is important to stay updated with the latest weather reports as conditions can change rapidly.\\n\\nReferences:\\n[1] https://www.mercurynews.com/2024/01/07/bay-area-and-beyond-frost-advisory-and-freeze-warning-monday-morning/\", 'initial_answer': \"The weather in San Francisco (SF) is characterized by a mild, Mediterranean-like climate with wet winters and dry summers. The city's unique topography and coastal location result in microclimates, where weather conditions can vary significantly from one neighborhood to another. Average temperatures typically range from the mid-40s to the low 70s Fahrenheit (7-22 degrees Celsius), with the warmest months being September and October. Fog is a common occurrence, particularly in the summer, often rolling in during the evening and clearing by midday. Rainfall is most frequent from November to March, while the rest of the year is relatively dry. Wind is another constant factor, with the afternoon sea breeze being a defining feature of the city's weather. Despite these general patterns, it's always advisable to check the current weather forecast before planning activities in San Francisco, as conditions can change rapidly.\"}, log='Reached max steps.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "# add actors\n",
    "workflow.add_node(\"initial\", initial_chain)\n",
    "workflow.add_node(\"next\", next_chain)\n",
    "workflow.add_node(\"finish\", finish)\n",
    "workflow.add_node(\"tools\", execute_tools)\n",
    "\n",
    "# Enter with initial actor, then loop through tools -> next steps until finished\n",
    "workflow.set_entry_point('initial')\n",
    "\n",
    "workflow.add_edge('initial', 'tools')\n",
    "workflow.add_conditional_edges(\n",
    "    'tools',\n",
    "    lambda x: \"exit\" if len(x['intermediate_steps']) >= 2 else \"continue\",\n",
    "    {\n",
    "        \"continue\": 'next',\n",
    "        \"exit\": 'finish'\n",
    "    }\n",
    ")\n",
    "workflow.add_edge('next', 'tools')\n",
    "workflow.set_finish_point('finish')\n",
    "\n",
    "chain = workflow.compile()\n",
    "\n",
    "chain.invoke({\"question\": \"what is the weather in sf\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23960c53-eacf-432c-b736-b93ed33d3ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
